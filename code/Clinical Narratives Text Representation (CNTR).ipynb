{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399e68b-ba41-47d2-82bc-d54ec12ae77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim.models import Word2Vec, word2vec, doc2vec\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "    \n",
    "def save_pickle(data, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f) \n",
    "\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b46336-5790-40fe-84c8-bdc3ee1c64c3",
   "metadata": {},
   "source": [
    "# Load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a696d-25f2-4ecf-9d6f-63c8a6c5df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pickle('./Data_Cleaned/171275_Cleaned.pickle')\n",
    "model_w2v = Word2Vec.load(\"./Extra_Feature/w2v_300d.model\")\n",
    "model_d2v = doc2vec.Doc2Vec.load(\"./Extra_Feature/d2v_300d.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2aa5c-20d7-4434-a102-82b5a09b4e7a",
   "metadata": {},
   "source": [
    "## Log Likelihood Ratio (LLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b6e7d-bc7f-483c-a0de-d01c4eebebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmunlp as nlp\n",
    "\n",
    "def save_txt(data_path, label, text):\n",
    "    with open(data_path, 'w', encoding='utf-8') as f:\n",
    "        for idx in range(len(label)):\n",
    "            f.write((str(label[idx])+'\\t'+str(text[idx])+'\\n'))\n",
    "\n",
    "    \n",
    "def get_LLR_keyword(data_path, label_list, number_of_kw):   \n",
    "    label_term_weighting = nlp.get_label_term_weighting(data_path, label_list)\n",
    "    kw_dicts = {}\n",
    "    for label in label_list:\n",
    "        kw = nlp.get_keyword(label, label_term_weighting, number_of_kw, True)\n",
    "        kw_dicts.update({label: kw})                     \n",
    "    return kw_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a42724-cf5a-4331-9960-46f98d4736c5",
   "metadata": {},
   "source": [
    "## Clinical Narratives Text Representation (CNTR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e216fd7-e4f5-45f3-9323-a115a3842f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def distinguish(text, kw_dict):\n",
    "    text_set = set(text.split())\n",
    "    keywords = kw_dict.keys()\n",
    "    num = 0\n",
    "    for kw in keywords:\n",
    "        if kw in text_set:\n",
    "            num += 1\n",
    "        else:\n",
    "            continue\n",
    "    return num\n",
    "\n",
    "\n",
    "def match(text, kw_dict):\n",
    "    feature = []\n",
    "    match_words = []\n",
    "    text_set = set(text.split())\n",
    "    for kw in kw_dict.keys():\n",
    "        if kw in text_set:\n",
    "            feature.append(kw_dict.get(kw)) \n",
    "            match_words.append(kw)\n",
    "        else:\n",
    "            feature.append(0)       \n",
    "    return feature, match_words\n",
    "\n",
    "\n",
    "def get_similarity(similarity_array):\n",
    "    double_list = similarity_array.tolist()\n",
    "    for one_list in double_list:\n",
    "        for num in one_list:\n",
    "            similarity = num            \n",
    "    return similarity\n",
    "\n",
    "\n",
    "def similarity_sorted(similarity_dict, num_of_similar):\n",
    "    top_word = []\n",
    "    top_similarity = []\n",
    "    rank = sorted(similarity_dict.items(), key=lambda x : x[1], reverse=True)\n",
    "    for i in range(num_of_similar):\n",
    "        top_word.append(rank[i][0])\n",
    "        top_similarity.append(rank[i][1])\n",
    "    top_similarity_dict = {k: v for k, v in zip(top_word, top_similarity)}\n",
    "    return top_similarity_dict\n",
    "\n",
    "\n",
    "def no_match(text, kw_dict, model_d2v, model_w2v, num_of_similar):\n",
    "    similarity_dict = {}\n",
    "    similar_kw_list = []\n",
    "    similar_weight_list = []     \n",
    "    text_vec = model_d2v.infer_vector(list(text))\n",
    "    for kw in kw_dict.keys():\n",
    "        kw_vec = model_w2v.wv[kw]\n",
    "        similarity_array = cosine_similarity([text_vec], [kw_vec]) \n",
    "        similarity_dict[kw] = get_similarity(similarity_array) \n",
    "    top_similarity_dict = similarity_sorted(similarity_dict, num_of_similar)        \n",
    "    for kw in kw_dict.keys(): \n",
    "        if kw in top_similarity_dict.keys():          \n",
    "            similar_weight_list.append(kw_dict.get(kw)*top_similarity_dict.get(kw))  \n",
    "            similar_kw_list.append(kw)\n",
    "        else:\n",
    "            similar_weight_list.append(0)            \n",
    "    return similar_weight_list, similar_kw_list\n",
    "\n",
    "\n",
    "def Transformation(texts, label, kw_dict, model_d2v, model_w2v, num_of_similar):\n",
    "    feature_output = []\n",
    "    words_output = []\n",
    "    feature_output_dict = {}\n",
    "    words_output_dict = {}\n",
    "    for index in range(len(texts)):\n",
    "        text = texts[index]  \n",
    "        num = distinguish(text, kw_dict)\n",
    "        if num > 0:\n",
    "            feature, match_words = match(text, kw_dict)\n",
    "            feature_output.append(feature)\n",
    "            words_output.append(match_words)\n",
    "        else:\n",
    "            similar_weight_list, similar_kw_list = no_match(text, kw_dict, model_d2v, model_w2v, num_of_similar)\n",
    "            feature_output.append(similar_weight_list)\n",
    "            words_output.append(similar_kw_list)\n",
    "    feature_output_dict.update({label: feature_output}) \n",
    "    words_output_dict.update({label: words_output}) \n",
    "    return feature_output_dict, words_output_dict\n",
    "\n",
    "\n",
    "def CNTR(df, column_label, column_LLR, path_LLR, label_list, number_of_kw, model_d2v, model_w2v, num_of_similar):  \n",
    "    CNTR_feature_dictionary = {}\n",
    "    CNTR_words_dictionary = {}\n",
    "    for index in range(len(column_LLR)):\n",
    "        column_name = column_LLR[index]\n",
    "        labels = df[column_label]\n",
    "        texts = df[column_name]\n",
    "        number = number_of_kw.get(column_name) \n",
    "        data_path = path_LLR.get(column_name)\n",
    "        \n",
    "        print(\"*** {} ***\".format(column_name))\n",
    "        if len(labels)==len(texts):\n",
    "            \n",
    "            print('** Log Likelihood Ratio **')\n",
    "            save_txt(data_path, labels, texts)  \n",
    "            kw_dicts = get_LLR_keyword(data_path, label_list, number)        \n",
    "            \n",
    "            print('** Transformation **')\n",
    "            CNTR_feature = {}\n",
    "            CNTR_words = {}       \n",
    "            for label in label_list:\n",
    "                kw_dict = kw_dicts.get(label)\n",
    "                feature_output_dict, words_output_dict = Transformation(texts, label, kw_dict, model_d2v, model_w2v, num_of_similar)\n",
    "                CNTR_feature.update(feature_output_dict) \n",
    "                CNTR_words.update(words_output_dict)                \n",
    "            CNTR_feature_dictionary.update({column_name: CNTR_feature}) \n",
    "            CNTR_words_dictionary.update({column_name: CNTR_words}) \n",
    "            \n",
    "        else:\n",
    "            print('Error!')\n",
    "            print('label: {}'.format(len(label)))\n",
    "            print('text: {}'.format(len(text)))\n",
    "            \n",
    "    return CNTR_feature_dictionary, CNTR_words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf3d80-0a67-4c3a-9064-55edae3b14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"1\", \"0\"]  \n",
    "column_label = 'code_final'\n",
    "column_LLR = ['Chief Complaint', 'Present lllness', 'Medical history']\n",
    "num_of_similar = 5\n",
    "\n",
    "path_LLR = {\n",
    "    column_LLR[0]: './Extra_Feature/for_LLR_chief.txt', \n",
    "    column_LLR[1]: './Extra_Feature/for_LLR_present.txt',\n",
    "    column_LLR[2]: './Extra_Feature/for_LLR_past.txt'\n",
    "}\n",
    "\n",
    "number_of_kw = {\n",
    "    column_LLR[0]: 100, \n",
    "    column_LLR[1]: 100,\n",
    "    column_LLR[2]: 15\n",
    "}\n",
    "\n",
    "\n",
    "CNTR_feature_dictionary, CNTR_words_dictionary = CNTR(df, column_label, column_LLR, path_LLR, label_list, number_of_kw, model_d2v, model_w2v, num_of_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c4656-2089-44aa-b77c-6516d1aff2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
